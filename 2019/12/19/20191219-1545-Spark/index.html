<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>20191219_1545_SPARK | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Spark 配置01. Spark Repo Pointspark-2.0.2-bin-hadoop2.6.tgz  02. 环境配置1. 环境包 rz 至相关路径，分流至其它节点：源码分发12scp -r &#x2F;usr&#x2F;local&#x2F;src&#x2F;spark-2.0.2-bin-hadoop2.6 root@slave1:&#x2F;usr&#x2F;local&#x2F;src&#x2F;scp -r &#x2F;usr&#x2F;local&#x2F;src&#x2F;spark-">
<meta property="og:type" content="article">
<meta property="og:title" content="20191219_1545_SPARK">
<meta property="og:url" content="http:&#x2F;&#x2F;yoursite.com&#x2F;2019&#x2F;12&#x2F;19&#x2F;20191219-1545-Spark&#x2F;index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="Spark 配置01. Spark Repo Pointspark-2.0.2-bin-hadoop2.6.tgz  02. 环境配置1. 环境包 rz 至相关路径，分流至其它节点：源码分发12scp -r &#x2F;usr&#x2F;local&#x2F;src&#x2F;spark-2.0.2-bin-hadoop2.6 root@slave1:&#x2F;usr&#x2F;local&#x2F;src&#x2F;scp -r &#x2F;usr&#x2F;local&#x2F;src&#x2F;spark-">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;2019&#x2F;12&#x2F;19&#x2F;20191219-1545-Spark&#x2F;Spark-error_metastore_beeline.png">
<meta property="article:published_time" content="2019-12-19T08:18:41.000Z">
<meta property="article:modified_time" content="2019-12-19T15:59:25.866Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="Spark">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;2019&#x2F;12&#x2F;19&#x2F;20191219-1545-Spark&#x2F;Spark-error_metastore_beeline.png">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 4.1.1"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-20191219-1545-Spark" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/12/19/20191219-1545-Spark/" class="article-date">
  <time datetime="2019-12-19T08:18:41.000Z" itemprop="datePublished">2019-12-19</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      20191219_1545_SPARK
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Spark-配置"><a href="#Spark-配置" class="headerlink" title="Spark 配置"></a>Spark 配置</h2><h3 id="01-Spark"><a href="#01-Spark" class="headerlink" title="01. Spark"></a>01. Spark</h3><ul>
<li>Repo Point<br><a href="http://archive.apache.org/dist/spark/spark-2.0.2/spark-2.0.2-bin-hadoop2.6.tgz" target="_blank" rel="noopener">spark-2.0.2-bin-hadoop2.6.tgz</a></li>
</ul>
<h3 id="02-环境配置"><a href="#02-环境配置" class="headerlink" title="02. 环境配置"></a>02. 环境配置</h3><h4 id="1-环境包-rz-至相关路径，分流至其它节点："><a href="#1-环境包-rz-至相关路径，分流至其它节点：" class="headerlink" title="1. 环境包 rz 至相关路径，分流至其它节点："></a>1. 环境包 rz 至相关路径，分流至其它节点：</h4><h5 id="源码分发"><a href="#源码分发" class="headerlink" title="源码分发"></a>源码分发</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp -r /usr/<span class="built_in">local</span>/src/spark-2.0.2-bin-hadoop2.6 root@slave1:/usr/<span class="built_in">local</span>/src/</span><br><span class="line">scp -r /usr/<span class="built_in">local</span>/src/spark-2.0.2-bin-hadoop2.6 root@slave2:/usr/<span class="built_in">local</span>/src/</span><br></pre></td></tr></table></figure>

<h4 id="2-用户环境变量配置"><a href="#2-用户环境变量配置" class="headerlink" title="2. 用户环境变量配置"></a>2. 用户环境变量配置</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SET JAVA PATH</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/<span class="built_in">local</span>/src/jdk1.8.0_201</span><br><span class="line"><span class="built_in">export</span> JRE_HOME=<span class="variable">$&#123;JAVA_HOME&#125;</span>/jre</span><br><span class="line"><span class="built_in">export</span> CLASSPATH=.:<span class="variable">$&#123;JAVA_HOME&#125;</span>/lib:<span class="variable">$&#123;JRE_HOME&#125;</span>/lib</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$&#123;JAVA_HOME&#125;</span>/bin:<span class="variable">$PATH</span></span><br><span class="line"><span class="comment"># SET HADOOP PATH</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/usr/<span class="built_in">local</span>/src/hadoop-2.6.1</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/bin</span><br><span class="line"><span class="comment"># SET HIVE PATH</span></span><br><span class="line"><span class="built_in">export</span> HIVE_HOME=/usr/<span class="built_in">local</span>/src/apache-hive-1.2.2-bin</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HIVE_HOME</span>/bin</span><br><span class="line"><span class="comment"># SET SCALA PATH</span></span><br><span class="line"><span class="built_in">export</span> SCALA_HOME=/usr/<span class="built_in">local</span>/src/scala-2.11.8</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$SCALA_HOME</span>/bin</span><br><span class="line"><span class="comment"># SET SPARK PATH</span></span><br><span class="line"><span class="built_in">export</span> SPARK_HOME=/usr/<span class="built_in">local</span>/src/spark-2.0.2-bin-hadoop2.6</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$SPARK_HOME</span>/bin:<span class="variable">$SPARK_HOME</span>/sbin</span><br><span class="line"></span><br><span class="line"><span class="comment"># SET INI PATH</span></span><br><span class="line"><span class="built_in">export</span> INI_PATH=/usr/<span class="built_in">local</span>/src</span><br></pre></td></tr></table></figure>
<h5 id="环境变量分发"><a href="#环境变量分发" class="headerlink" title="环境变量分发"></a>环境变量分发</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp ~/.bashrc root@slave1:~/</span><br><span class="line">scp ~/.bashrc root@slave2:~/</span><br></pre></td></tr></table></figure>

<h4 id="3-修改-SPARK-源码环境配置文件、添加集群节点："><a href="#3-修改-SPARK-源码环境配置文件、添加集群节点：" class="headerlink" title="3. 修改 SPARK 源码环境配置文件、添加集群节点："></a>3. 修改 SPARK 源码环境配置文件、添加集群节点：</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/src/spark-2.0.2-bin-hadoop2.6/conf/</span><br><span class="line">mv spark-env.sh.template spark-env.sh</span><br><span class="line">vim spark-env.sh</span><br><span class="line"><span class="comment"># spark-env.sh</span></span><br><span class="line"><span class="built_in">export</span> SCALA_HOME=/usr/<span class="built_in">local</span>/src/scala-2.11.8</span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/<span class="built_in">local</span>/src/jdk1.8.0_201</span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/usr/<span class="built_in">local</span>/src/hadoop-2.6.1</span><br><span class="line"><span class="built_in">export</span> HADOOP_CONF_DIR=/usr/<span class="built_in">local</span>/src/hadoop-2.6.1/etc/hadoop</span><br><span class="line">SPARK_MASTER_IP=master</span><br><span class="line">SPARK_LOCAL_DIRS=/usr/<span class="built_in">local</span>/src/spark-2.0.2-bin-hadoop2.6</span><br><span class="line">SPARK_DRIVER_MEMORY=1G</span><br><span class="line"><span class="comment">######</span></span><br><span class="line"></span><br><span class="line">mv slaves.template slaves</span><br><span class="line">vim slaves</span><br><span class="line"><span class="comment"># slaves 添加集群节点</span></span><br><span class="line">slave1</span><br><span class="line">slave2</span><br><span class="line"><span class="comment">######</span></span><br></pre></td></tr></table></figure>

<h4 id="4-适配Spark-SQL"><a href="#4-适配Spark-SQL" class="headerlink" title="4. 适配Spark-SQL"></a>4. 适配Spark-SQL</h4><h5 id="MySQL相关配置和赋权见相关Blog，此处暂时不进行罗列：MySQL配置"><a href="#MySQL相关配置和赋权见相关Blog，此处暂时不进行罗列：MySQL配置" class="headerlink" title="MySQL相关配置和赋权见相关Blog，此处暂时不进行罗列：MySQL配置"></a>MySQL相关配置和赋权见相关Blog，此处暂时不进行罗列：<a href="">MySQL配置</a></h5><p>修改 $HIVE_HOME/bin下的Hive启动脚本 <strong><code>hive</code></strong>：<br><code>Tips</code> <strong>SPARK2.0</strong> 中没有 <code>${SPARK_HOME}/lib/spark-assembly-*.jar</code>，<strong>lib</strong>文件中的jar包已经被分成多个小的jar包在放置在 <code>${SPARK_HOME}/jars/</code> 下.</p>
<h5 id="修改前："><a href="#修改前：" class="headerlink" title="修改前："></a>修改前：</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># add SPARK assembly jar to the classpath</span></span><br><span class="line"><span class="keyword">if</span> [[ -n <span class="string">"<span class="variable">$SPARK_HOME</span>"</span> ]]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">  sparkAssemblyPath=`ls <span class="variable">$&#123;SPARK_HOME&#125;</span>/lib/spark-assembly-*.jar`</span><br><span class="line">  CLASSPATH=<span class="string">"<span class="variable">$&#123;CLASSPATH&#125;</span>:<span class="variable">$&#123;sparkAssemblyPath&#125;</span>"</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>

<h5 id="YARN-Hadoop-2-0-内的："><a href="#YARN-Hadoop-2-0-内的：" class="headerlink" title="YARN (Hadoop 2.0) 内的："></a>YARN (Hadoop 2.0) 内的：</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># add SPARK assembly jar to the classpath</span></span><br><span class="line"><span class="keyword">if</span> [[ -n <span class="string">"<span class="variable">$SPARK_HOME</span>"</span> ]]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">  sparkAssemblyPath=`ls <span class="variable">$&#123;SPARK_HOME&#125;</span>/jars/*.jar`</span><br><span class="line">  CLASSPATH=<span class="string">"<span class="variable">$&#123;CLASSPATH&#125;</span>:<span class="variable">$&#123;sparkAssemblyPath&#125;</span>"</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>

<h4 id="5-更新Hadoop-Yarn下的老版-jline-0-9-94-jar"><a href="#5-更新Hadoop-Yarn下的老版-jline-0-9-94-jar" class="headerlink" title="5. 更新Hadoop Yarn下的老版 jline-0.9.94.jar"></a>5. 更新Hadoop Yarn下的老版 <strong>jline-0.9.94.jar</strong></h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Hive内较新版本的jline替换Hadoop内的OLD版本</span></span><br><span class="line"><span class="built_in">cd</span> <span class="variable">$HADOOP_HOME</span>/share/hadoop/yarn/lib/</span><br><span class="line">mv jline-0.9.94.jar jline-0.9.94.jar.old</span><br><span class="line">cp <span class="variable">$HIVE_HOME</span>/lib/jline-2.12.jar <span class="variable">$HADOOP_HOME</span>/share/hadoop/yarn/lib/</span><br></pre></td></tr></table></figure>

<h4 id="6-Hive集成Spark-SQL"><a href="#6-Hive集成Spark-SQL" class="headerlink" title="6. Hive集成Spark-SQL"></a>6. Hive集成Spark-SQL</h4><p><code>Tips</code> 这部分集成后的功能暂未进行操作</p>
<h5 id="hive-site-xml-内新增-Metastore-配置"><a href="#hive-site-xml-内新增-Metastore-配置" class="headerlink" title="hive-site.xml 内新增 Metastore 配置"></a>hive-site.xml 内新增 Metastore 配置</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">vim <span class="variable">$HIVE_HOME</span>/conf/hive-site.xml</span><br><span class="line"><span class="comment"># hive-site.xml 新增如下内容：</span></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;hive.metastore.uris&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;thrift://hostname:9083&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"><span class="comment">######</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将Hive的配置文件拷贝给SPARK</span></span><br><span class="line">cp <span class="variable">$HIVE_HOME</span>/conf/hive-site.xml <span class="variable">$SPARK_HOME</span>/conf/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将MySQL下的jdbc驱动包拷贝给SPARK</span></span><br><span class="line">cp <span class="variable">$HIVE_HOME</span>/lib/mysql-connector-java-5.1.44.jar  <span class="variable">$SPARK_HOME</span>/jars/</span><br></pre></td></tr></table></figure>

<h4 id="7-SPARK集群启动-关闭"><a href="#7-SPARK集群启动-关闭" class="headerlink" title="7. SPARK集群启动/关闭"></a>7. SPARK集群启动/关闭</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/src/spark-2.0.2-bin-hadoop2.6/sbin/</span><br><span class="line">./start-all.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭集群：</span></span><br><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/src/spark-2.0.2-bin-hadoop2.6/sbin/</span><br><span class="line">./stop-all.sh</span><br></pre></td></tr></table></figure>

<h5 id="启动-Hive-metastore"><a href="#启动-Hive-metastore" class="headerlink" title="启动 Hive metastore"></a>启动 Hive metastore</h5><p><code>Metedata</code>元数据.<br><code>Metastore</code>Hive客户端连接Metastore元存储服务，Metastore再去连接MySQL来存取 <strong>元数据</strong>。多个客户端连接Hive时，只需要连接Metastore服务即可；即启动后可以用Java、Python等调用该jdbc</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># hive --service metastore</span></span><br><span class="line"><span class="built_in">cd</span> <span class="variable">$HIVE_HOME</span>/bin/</span><br><span class="line">hive --service metastore  1&gt;/dev/null  2&gt;&amp;1  &amp;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动Spark-SQL的shell交互界面</span></span><br><span class="line"><span class="built_in">cd</span> <span class="variable">$SPARK_HOME</span>/bin/</span><br><span class="line">spark-shell --master spark://master:7077</span><br></pre></td></tr></table></figure>
<h5 id="疑问"><a href="#疑问" class="headerlink" title="疑问"></a>疑问</h5><p><code>hiveserver2</code>HS2是一个服务端接口，使远程客户端可以执行对Hive的查询并返回结果，HS2提供了新的CLI：Beeline(基于SQLLine)，可以作为Hive jdbc Client端访问HS2.<br><code>hiveserver2</code> 和 <code>Metastore</code>一样同为Thrift Service，区别是否在于前者访问数据，后者访问元数据？？？</p>
<ul>
<li>网上有一部分解释：</li>
</ul>
<ol>
<li><p>若有在 <code>hive-site.xml</code> 中配置 <code>hive.metastore.uris</code>，则 <code>hiveserver2</code> 启动时会去连接配置好的 Metastore 服务(故需开启Metastore服务，其余jdbc访问也需开启该服务)，这种方式最为常用；</p>
</li>
<li><p>配置情况下未启动 <code>Metastore</code>，本地Beeline Client连接会失败；<img src="Spark-error_metastore_beeline.png" alt="配置MS但未开启时，Beeline报错." title="配置MS但未开启时，Beeline报错."> </p>
</li>
<li><p>若未配置，则启动HS2时，会先启动一个 <code>Metastore</code> 服务，然后再启动HS2，便于后续Beeline CLI的连接.</p>
</li>
<li></li>
</ol>
<h5 id="回顾下Beeline连接Hive"><a href="#回顾下Beeline连接Hive" class="headerlink" title="回顾下Beeline连接Hive"></a>回顾下Beeline连接Hive</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 配置了hive.metastore.uris后需开启 Metastore</span></span><br><span class="line"><span class="comment"># 后缀为重定向，需百度解决</span></span><br><span class="line">hive --service metastore  1&gt;/dev/null  2&gt;&amp;1  &amp;</span><br><span class="line"><span class="comment"># beeline方式连接Hive，默认端口为10000</span></span><br><span class="line">hive --service hiveserver2</span><br><span class="line"><span class="comment">#beeline</span></span><br><span class="line"><span class="comment">#!connect jdbc:hive2://master:10000 root 123456</span></span><br><span class="line">beeline -u jdbc:hive2://master:10000 -n root -p 123456 --color=<span class="literal">true</span></span><br></pre></td></tr></table></figure>

<p><code>Tips</code> 可以单独启动 SPARK 集群，但此时无ResourceManager/NodeManager等进程！！！</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/12/19/20191219-1545-Spark/" data-id="ck4cxc7zy0007jwu671wch50t" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark/" rel="tag">Spark</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2019/12/19/20191219-2254-Hive-1-x/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          20191219-2254_Hive-1.x
        
      </div>
    </a>
  
  
    <a href="/2019/12/19/20191219-1545-ZooKeeper-Kafka/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">20191219_1545_ZooKeeper-Kafka</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hadoop-2-X/" rel="tag">Hadoop 2.X</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hive/" rel="tag">Hive</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PracticeDemo/" rel="tag">PracticeDemo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python3/" rel="tag">Python3</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Spark/" rel="tag">Spark</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ZooKeeper-Kafka/" rel="tag">ZooKeeper Kafka</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Hadoop-2-X/" style="font-size: 10px;">Hadoop 2.X</a> <a href="/tags/Hive/" style="font-size: 10px;">Hive</a> <a href="/tags/PracticeDemo/" style="font-size: 10px;">PracticeDemo</a> <a href="/tags/Python3/" style="font-size: 10px;">Python3</a> <a href="/tags/Spark/" style="font-size: 10px;">Spark</a> <a href="/tags/ZooKeeper-Kafka/" style="font-size: 10px;">ZooKeeper Kafka</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/12/19/20191219-2347-Hadoop-2-6-1/">20191219-2347_Hadoop-2.6.1</a>
          </li>
        
          <li>
            <a href="/2019/12/19/20191219-2254-Hive-1-x/">20191219-2254_Hive-1.x</a>
          </li>
        
          <li>
            <a href="/2019/12/19/20191219-1545-Spark/">20191219_1545_SPARK</a>
          </li>
        
          <li>
            <a href="/2019/12/19/20191219-1545-ZooKeeper-Kafka/">20191219_1545_ZooKeeper-Kafka</a>
          </li>
        
          <li>
            <a href="/2019/12/18/20191218-2224-MURA-Excel/">20191218-2224-MURA-Excel</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>